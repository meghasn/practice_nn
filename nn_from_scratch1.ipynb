{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn_from_scratch1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "coding a neuron- in a fully connected network every neuron has a connection to every other neurons- let us consider 3 neurons\n",
        "\n",
        "inputs can depict different type of inputs eg, op from temp sensor, humidity sensor etc\n"
      ],
      "metadata": {
        "id": "9-ZRlooTImsS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3AxOUeiIfJM",
        "outputId": "c3b5a41a-0537-4007-a39b-f3a98393ebe4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.8"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "inputs=[1,2,3,2.5]#output from previous layer\n",
        "weights=[.2,.8,-.5,1.0]#every input have wts\n",
        "bias=2#unique val for a layer\n",
        "output=inputs[0]*weights[0]+inputs[1]*weights[1]+inputs[2]*weights[2]+inputs[3]*weights[3]+bias\n",
        "output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "each neuron with corresponding weightsets, input and bias"
      ],
      "metadata": {
        "id": "k1N-szpp082V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=[1,2,3,2.5]#output from previous layer\n",
        "\n",
        "weights1=[.2,.8,-.5,1.0]#every input have wts\n",
        "weights2=[.5,-.91,.25,-.5]\n",
        "weights3=[-.26,-.27,.17,.87]\n",
        "bias1=2#unique val for a layer\n",
        "bias2=3\n",
        "bias3=.5\n",
        "output=[inputs[0]*weights1[0]+inputs[1]*weights1[1]+inputs[2]*weights1[2]+inputs[3]*weights1[3]+bias1,inputs[0]*weights2[0]+inputs[1]*weights2[1]+inputs[2]*weights2[2]+inputs[3]*weights2[3]+bias2,inputs[0]*weights3[0]+inputs[1]*weights3[1]+inputs[2]*weights3[2]+inputs[3]*weights3[3]+bias3]\n",
        "output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbTci9Gq1A7g",
        "outputId": "104cddc2-14f6-445d-eb2a-104f6f891624"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.8, 1.18, 2.385]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "put it in a loop"
      ],
      "metadata": {
        "id": "86yB4cDHeDQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=[1,2,3,2.5]\n",
        "weights=[[.2,.8,-.5,1.0],[.5,-.91,.25,-.5],[-.26,-.27,.17,.87]]\n",
        "biases=[2,3,.5]\n",
        "layer_outputs=[]\n",
        "for nw,nb in zip(weights,biases):\n",
        "  neuron_output=0\n",
        "  for ip,wt in zip(inputs,nw):\n",
        "    neuron_output+=ip*wt#sum of w*x's\n",
        "  neuron_output+=nb#complete sigma(w*x+b)\n",
        "  layer_outputs.append(neuron_output)\n",
        "print(layer_outputs)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpu4tSEjdypT",
        "outputId": "b79e0da7-20fc-4d12-ea53-3b8971752ebf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.8, 1.18, 2.385]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding shapes\n",
        "\n",
        "\n",
        "vectors, scalars, tensors"
      ],
      "metadata": {
        "id": "4nRiDot1gYhp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1D\n",
        "\n",
        "eg:[1,2,3,4]\n",
        "\n",
        "shape=(4,)\n",
        "\n",
        "type:vector"
      ],
      "metadata": {
        "id": "arW9J9tykD6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2D\n",
        "\n",
        "eg:[[1,2,3,4],[5,6,7,8]]\n",
        "\n",
        "shape:(2,4)\n",
        "\n",
        "type:matrix"
      ],
      "metadata": {
        "id": "QPGbmvbrkWNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3D\n",
        "\n",
        "eg:[[[1,2,3,4],[5,6,7,8]],[[1,2,3,4],[5,6,7,8]]\n",
        "\n",
        "shape:(2,2,4)\n",
        "\n",
        "type:3d array"
      ],
      "metadata": {
        "id": "Ry75NVywkx0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "dot poduct- element wise multiplication of values in this \n",
        "\n",
        "dot product of 2 vectors gives a single scalar value"
      ],
      "metadata": {
        "id": "kbGHCdmPZ-LH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "inputs=[1,2,3,2.5]#vector\n",
        "weights=[.2,.8,-.5,1.0]#matrix\n",
        "bias=2#vector\n",
        "output=np.dot(inputs,weights)+bias\n",
        "output"
      ],
      "metadata": {
        "id": "F04kL3L2gddF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0e0921-d3e3-41b2-cfd8-2925db61003e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.8"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DOT PRODUCT- layer"
      ],
      "metadata": {
        "id": "HXrRlGcFbi9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=[1,2,3,2.5]#(4,1)\n",
        "weights=[[.2,.8,-.5,1.0],[.5,-.91,.25,-.5],[-.26,-.27,.17,.87]]#(3,4)\n",
        "biases=[2,3,.5]#(3,1)\n",
        "output=np.dot(weights,inputs)+biases#(3,4)*(4,1)=(3,1)+(3,1)=(3,1)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaFUVCFdbikP",
        "outputId": "b2dc4cf0-9d6b-4332-e315-ab5e52e02897"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.8  , 1.18 , 2.385])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WHY BATCHES?\n",
        "\n",
        "1. We can compute in parallel\n",
        "\n",
        "2. it helps with generalization\n",
        "\n",
        "when we take batches, we are going to consider batch of samples at different intances\n",
        "\n",
        "batch size- generally- 32,64,128 etc"
      ],
      "metadata": {
        "id": "cdYQb7vonzDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=[[1,2,3,2.5],[2.0,5.0,-1.0,2.0],[-1.5,2.7,3.3,-.8]]#(3,4)\n",
        "weights=[[.2,.8,-.5,1.0],[.5,-.91,.25,-.5],[-.26,-.27,.17,.87]]#(3,4)\n",
        "biases=[2,3,.5]#(3,1)\n",
        "#(3,4)*(3,4) not be done\n",
        "#this can be done if (3,4),(4,3) therefore take transpose of wts\n",
        "output=np.dot(inputs,np.array(weights).T)+biases\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHS_rGAEpzmL",
        "outputId": "ddb686ef-cd2a-4c3d-8c95-5d0beaa982d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.8  ,  1.18 ,  2.385],\n",
              "       [ 8.9  , -1.8  ,  0.2  ],\n",
              "       [ 1.41 ,  1.018,  0.026]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADD LAYERS\n",
        "\n"
      ],
      "metadata": {
        "id": "4Vi7msJltGxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=[[1,2,3,2.5],[2.0,5.0,-1.0,2.0],[-1.5,2.7,3.3,-.8]]#(3,4)\n",
        "weights=[[.2,.8,-.5,1.0],[.5,-.91,.25,-.5],[-.26,-.27,.17,.87]]#(3,4)\n",
        "biases=[2,3,.5]#(3,1)\n",
        "weights2=[[.1,-.14,.5],[-.5,.12,-.33],[-.44,.73,-.13]]#(3,4)\n",
        "biases2=[-1,2,-.5]#(3,1)\n",
        "#(3,4)*(3,4) not be done\n",
        "#this can be done if (3,4),(4,3) therefore take transpose of wts\n",
        "layer1_op=np.dot(inputs,np.array(weights).T)+biases\n",
        "layer2_op=np.dot(layer1_op,np.array(weights2).T)+biases2\n",
        "layer2_op"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_tXnrdxtSG1",
        "outputId": "623e65d7-1604-47fe-e7b5-dd8aed7762cf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.5073 , -1.04545, -2.06065],\n",
              "       [ 0.242  , -2.732  , -5.756  ],\n",
              "       [-0.98852,  1.40858, -0.38064]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ORGANIZE THE ABOVE CODE- AS OBJECTS\n",
        "\n",
        "when you save and load a model, you are actually loading the trained weights and the biases\n",
        "\n",
        "when we initialize wts we choose values btwn -1 and 1 , but smaller the wts better it perform\n",
        "\n",
        "biases we tend to initialize them as 0(on the graph bias is the intercept)"
      ],
      "metadata": {
        "id": "-RZx83CZuCln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "X=[[1,2,3,2.5],[2.0,5.0,-1.0,2.0],[-1.5,2.7,3.3,-.8]]#(3,4)->input\n",
        "class Layer_Dense:\n",
        "  def __init__(self,n_inputs,n_neurons):\n",
        "    self.weights=.1*np.random.randn(n_inputs,n_neurons)#randn is just a gaussian distribution around 0, if values are more than  1 multiply by .1\n",
        "    self.biases=np.zeros((1,n_neurons))\n",
        "  def forward(self,inputs):\n",
        "    self.output=np.dot(inputs,self.weights)+self.biases\n",
        "    \n",
        "layer1=Layer_Dense(len(X[0]),5)\n",
        "layer2=Layer_Dense(5,2)\n",
        "layer1.forward(X)\n",
        "print(layer1.output)\n",
        "layer2.forward(layer1.output)\n",
        "print(layer2.output)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeJdJw9tuRw5",
        "outputId": "ab3f705d-ade3-4ccc-ef23-4e7fbc81532c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.10758131  1.03983522  0.24462411  0.31821498  0.18851053]\n",
            " [-0.08349796  0.70846411  0.00293357  0.44701525  0.36360538]\n",
            " [-0.50763245  0.55688422  0.07987797 -0.34889573  0.04553042]]\n",
            "[[ 0.148296   -0.08397602]\n",
            " [ 0.14100315 -0.01340469]\n",
            " [ 0.20124979 -0.07290616]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ACTIVATION FUNCTION\n",
        "\n",
        "1. step fn\n",
        "2. sigmoid fn(issue- vanishing gradient)\n",
        "3. relu fn\n",
        "4. linear activation\n"
      ],
      "metadata": {
        "id": "zGwDodGOF_k4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "X=[[1,2,3,2.5],[2.0,5.0,-1.0,2.0],[-1.5,2.7,3.3,-.8]]#(3,4)->input\n",
        "inputs=[0,2,-1,3.3,-2.7,1.1,2.2,-100]\n",
        "output=[]\n",
        "for i in inputs:\n",
        "  if i>0:\n",
        "    output.append(i)\n",
        "  elif i<=0:\n",
        "    output.append(0)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHLA1sVESSxU",
        "outputId": "eb51d926-4359-4bd7-8dc0-eda7bca9922d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 2, 0, 3.3, 0, 1.1, 2.2, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nnfs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROMQnwEsXIaO",
        "outputId": "c1d8d31b-7714-44dc-a445-e2b34e40e68c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnfs\n",
            "  Downloading nnfs-0.5.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nnfs) (1.21.5)\n",
            "Installing collected packages: nnfs\n",
            "Successfully installed nnfs-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Relu object"
      ],
      "metadata": {
        "id": "AvCWwYR7TV79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "X,y=spiral_data(100,3)\n",
        "class activation_relu:\n",
        "  def forward(self,inputs):\n",
        "    self.output=np.maximum(0,inputs)\n",
        "class Layer_Dense:\n",
        "  def __init__(self,n_inputs,n_neurons):\n",
        "    self.weights=.1*np.random.randn(n_inputs,n_neurons)#randn is just a gaussian distribution around 0, if values are more than  1 multiply by .1\n",
        "    self.biases=np.zeros((1,n_neurons))\n",
        "  def forward(self,inputs):\n",
        "    self.output=np.dot(inputs,self.weights)+self.biases\n",
        "    \n",
        "layer1=Layer_Dense(2,5)# this is a data for spiral graph therefore x and y cordinates will be the 2 features\n",
        "activation1=activation_relu()\n",
        "layer1.forward(X)\n",
        "activation1.forward(layer1.output)\n",
        "print(activation1.output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5Pjed_TTYeL",
        "outputId": "37286a31-72f0-4073-e1e4-7d6f7202d57e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.65504526e-04\n",
            "  4.56845892e-05]\n",
            " [0.00000000e+00 5.93467943e-05 0.00000000e+00 2.03573189e-04\n",
            "  6.10024276e-04]\n",
            " ...\n",
            " [1.13291515e-01 0.00000000e+00 0.00000000e+00 8.11079627e-02\n",
            "  0.00000000e+00]\n",
            " [1.34588354e-01 0.00000000e+00 3.09493973e-02 5.66337522e-02\n",
            "  0.00000000e+00]\n",
            " [1.07817915e-01 0.00000000e+00 0.00000000e+00 8.72561871e-02\n",
            "  0.00000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Softmax function\n",
        "\n",
        "specifically used for the output layer of classification type nn\n"
      ],
      "metadata": {
        "id": "zMMctcghLKIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "layer_output=[4.8,1.21,2.385]\n",
        "E=math.e\n",
        "output=[]\n",
        "for op in layer_output:\n",
        "  output.append(E**op)\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaRnbKl7Lx17",
        "outputId": "032834d9-221e-4e5d-ddaa-fffb8dbe72ec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[121.51041751873483, 3.353484652549023, 10.859062664920513]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "normalize-exponentiated values\n",
        "\n",
        "combination of exponentiation and normalization makes up softmax"
      ],
      "metadata": {
        "id": "n6bTEuIpUSWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "layer_output=[4.8,1.21,2.385]\n",
        "E=math.e\n",
        "output=[]\n",
        "for op in layer_output:\n",
        "  output.append(E**op)\n",
        "print(output)\n",
        "norm_value=[]\n",
        "norm_base=sum(output)\n",
        "for values in output:\n",
        "  norm_value.append(values / norm_base)\n",
        "print(norm_value)\n",
        "print(sum(norm_value))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q4qILEPUVqb",
        "outputId": "828a5a6a-2b0c-4240-c19b-644c631af646"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[121.51041751873483, 3.353484652549023, 10.859062664920513]\n",
            "[0.8952826639572619, 0.024708306782099374, 0.0800090292606387]\n",
            "0.9999999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "layer_output=[4.8,1.21,2.385]\n",
        "E=math.e\n",
        "output=np.exp(layer_output)\n",
        "norm_values= output/np.sum(output)\n",
        "\n",
        "print(norm_value)\n",
        "print(sum(norm_value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75yCEsksVosb",
        "outputId": "9f6eed6d-bef0-4f23-9319-6e8c46f41386"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8952826639572619, 0.024708306782099374, 0.0800090292606387]\n",
            "0.9999999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use softmax fn- for batch ip\n",
        "\n",
        "note: axis parameter - none, default-take the sum of all values\n",
        "\n",
        "0, column wise-> 1, row wise\n",
        "\n",
        "note: keepdims=True, maintains the same dimension"
      ],
      "metadata": {
        "id": "H3mQjFgW7Eq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "input=[[4.8,1.21,2.385],[8.9,-1.81,0.2],[1.41,1.051,0.026]]\n",
        "layer_output=np.exp(input)\n",
        "sum=np.sum(layer_output, axis=1, keepdims=True)\n",
        "norm_values= output/sum\n",
        "print(norm_values)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0Kr2rOz7HJK",
        "outputId": "58064b5c-88ec-40c6-fa5c-9237d613014e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8.95282664e-01 2.47083068e-02 8.00090293e-02]\n",
            " [1.65695453e-02 4.57291786e-04 1.48077617e-03]\n",
            " [1.52215160e+01 4.20088428e-01 1.36030638e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "use softmax activation class"
      ],
      "metadata": {
        "id": "LyUybp5K-vjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "X,y=spiral_data(100,4)\n",
        "class activation_relu:\n",
        "  def forward(self,inputs):\n",
        "    self.output=np.maximum(0,inputs)\n",
        "class Layer_Dense:\n",
        "  def __init__(self,n_inputs,n_neurons):\n",
        "    self.weights=.1*np.random.randn(n_inputs,n_neurons)#randn is just a gaussian distribution around 0, if values are more than  1 multiply by .1\n",
        "    self.biases=np.zeros((1,n_neurons))\n",
        "  def forward(self,inputs):\n",
        "    self.output=np.dot(inputs,self.weights)+self.biases\n",
        "class activation_softmax:\n",
        "  def forward(self,inputs):\n",
        "    exp_values=np.exp(inputs-np.max(inputs,axis=1,keepdims=True))\n",
        "    probabilities=exp_values/np.sum(exp_values, axis=1, keepdims=True)\n",
        "    self.output=probabilities\n",
        "\"\"\"\n",
        "define the layers\n",
        "\"\"\"\n",
        "dense1=Layer_Dense(2,3)\n",
        "activation1=activation_relu()\n",
        "dense2=Layer_Dense(3,3)#ip is the op of prev layer\n",
        "activation2=activation_softmax()\n",
        "\"\"\"\n",
        "start propagation\n",
        "\"\"\"\n",
        "dense1.forward(X)\n",
        "activation1.forward(dense1.output)\n",
        "dense2.forward(activation1.output)\n",
        "activation2.forward(dense2.output)\n",
        "print(activation2.output)"
      ],
      "metadata": {
        "id": "h5QQLy3C-yh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fbbece9-738b-4a96-ef26-b31e7c94434b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.33333333 0.33333333 0.33333333]\n",
            " [0.3333299  0.33333811 0.33333199]\n",
            " [0.33333667 0.33334203 0.3333213 ]\n",
            " ...\n",
            " [0.33333333 0.33333333 0.33333333]\n",
            " [0.33318544 0.33325489 0.33355967]\n",
            " [0.33333333 0.33333333 0.33333333]]\n"
          ]
        }
      ]
    }
  ]
}